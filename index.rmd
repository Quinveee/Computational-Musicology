---
title: "Spotify Analysis"
output:
  flexdashboard::flex_dashboard:
    orientation: columns
    source_code: "https://github.com/Quinveee/Computational-Musicology"
    theme:
      version: 4
      bootswatch: minty
    vertical_layout: scroll
    css: style.css
---

```{=html}
<style>
.dataTables_scrollBody {
    height:540px !important;
}
.chart-stage-flex {
    overflow:auto !important;
}
</style>
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidytext)
library(tidyverse)
library(spotifyr)
library(flexdashboard)
library(plotly)
library(compmus)
library(DT)

corpus <- get_playlist_audio_features("", "75LhP6wXfee0eYHuW28nkw")
corpus |>
  summarise(
    mean_speechiness = mean(speechiness),
    mean_acousticness = mean(acousticness),
    mean_liveness = mean(liveness),
    sd_speechiness = sd(speechiness),
    sd_acousticness = sd(acousticness),
    sd_liveness = sd(liveness),
    median_speechiness = median(speechiness),
    median_acousticness = median(acousticness),
    median_liveness = median(liveness),
    mad_speechiness = mad(speechiness),
    mad_acousticness = mad(acousticness),
    mad_liveness = mad(liveness)
  )
```

# Corpus

## Column

### Corpus Description {style="min-height:400px"}

The corpus for this musical analysis consists of a collection of albums (see Appendix) that I chose based on my personal interest. I chose albums specifically, as it is the form in which I consume most of my music, but it will also ensure that the overlap in musical genres is more consistent between songs. This does however mean that the analysis will focus more on the difference between the albums as opposed to differences between individual songs. As for the corpus, it consists of a variety of genres including rock, pop, post-rock, ambient, shoegaze, neo-psychedelia, hip-hop. At first glance it might seem as if there is little overlap between the album’s genres, however, most can be categorized in either rock, ambient, pop, or hip-hop. Though there are some album’s that can be considered atypical for these categories, for example LONG SEASON by the Fishmans. This album consists of a single 35-minute song and incorporates a variety of genres into one. Another example is REGRET WHEN IT WAS LOST by death’s dynamic shroud which at points blurs the line between surrealism and music. Or F# A# ∞ by Godspeed You! Black Emperor, an album containing multiple monologues throughout the song creating an eerie vibe. I chose to incorporate these albums not only because they are some of my personal favorites but also for their uniqueness, which should hopefully lead to a more interesting analysis. The corpus contains many more such examples, which I will cover further in the analysis. However, most of the corpus consists of more typical genre representative albums, for example the albums made by; Radiohead, No Party For Coa Dong, tricot, Pink Floyd, Polyphia and Panchiko, are more typical to rock. So, all in all, the corpus consists of a combination of typical and atypical albums which should lead to an interesting analysis of the distinctions an overlap between genres and individual albums/songs.

### Appendix (album - artist)

```{r, echo=FALSE}
appendix <- corpus %>%
  select(track.album.name, track.artists, track.name, track.album.release_date)

artists <- lapply(appendix$track.artists, function(x) x$name)

for( i in 1:nrow(appendix)){
  name <- artists[i][[1]]
  
  if (length(name) > 1){
    for(j in length(name)){
      name <- paste(name[j-1], name[j], sep = ", ")
    }
  }
  
  appendix[i, "artist"] <- name
}

appendix <- subset(appendix, select = -track.artists)

artistAlbumGenre_df <- appendix %>%
  select(track.album.name, artist) %>%
  unique()

artistAlbumGenre_df$genre = NA

for (i in 1:nrow(artistAlbumGenre_df)) {

  artist <- artistAlbumGenre_df$artist[i]

  if (grepl(",", artist)) {

    str <- strsplit(artist,", ")[[1]]

    for (j in str) {
      
      temp <- as.list(search_spotify(j, 'artist')[[1]][1])
      
      if (artistAlbumGenre_df[i, "genre"][[1]][1]  == "NULL" & identical(temp, character(0)) == FALSE) {
        artistAlbumGenre_df[i, "genre"] <- list(temp)
      }
      else if (identical(temp, character(0)) == FALSE) {
        artistAlbumGenre_df[i, "genre"] <- list(list(unique(append(artistAlbumGenre_df[i, "genre"][[1]][[1]], temp[[1]]))))
      }
    }
  }
  else {
    artistAlbumGenre_df[i, "genre"] <- list(search_spotify(artist, 'artist')[[1]][1])
  }
}

```

```{r, echo=FALSE}

appendix <- merge(appendix, artistAlbumGenre_df)

appendix <- appendix %>% select(track.album.name, track.name, track.album.release_date, artist, genre)

datatable(appendix, style = "auto", colnames = c("Album", "Track Name", "Release Date", "Artist", "Genre"))
```

# Global Analysis {data-navmenu="Analysis" data-orientation=rows}

## Row {style="min-height:600px"}

### Description {data-width="350"} 

#### Analysis over the entire range of songs

The multivariate analysis plot shows a comparison of the liveness, acousticness and the speechness of each individual song. What is interesting about the plot is that there appears to be very little acousticness and speechness. This is relatively odd as many of the songs should contain speech, furthermore, the liveness seems rather low, possibly due to the amount of ambient music, but what is then even more odd is the fact that many of the songs with the highest liveness are ambient songs (this may be due to Spotify's algorithm not fully comprehending ambient music). The acousticness on the other hand seems all over the place, likely due to the fast differences in genres.

#### Differences in energy

The energy ranking plot below shows the mean energy levels of all albums in descending order. What is interesting about this plot is that the albums seems to contain nearly the entire range of the energy spectrum, all the way from A I A: Alien Observer at a level of around 0.13 to World is Yours at almost 1, with an overall mean of around 0.6.

#### Differences in acousticness

The acousticness ranking shows the mean acousticness levels of all albums in descending order, the pattern of which appears to be the complete opposite of the energy ranking, with most ambient leaning albums at the top of the chart and rock leaning albums to the bottom. 
For the rock to have a low acousticness seems very normal, as many rock albums use electric guitars, basses, synthesizers etc. However, for ambient leaning albums to be ranked so high on acousticness seems strange. Take for instance 新しい日の誕生 (the album with the second highest acousticness), an album that can be classified as ambient/ dreampunk that has almost no acousticness to it, in fact the only part that seems acoustic is the drums that play in the background of some songs, the rest is all clearly non-acoustic. 
This classification clearly encapsulates the limitations to the Spotify api, namely; Spotify does not give enough information on how the different attributes are calculated and what they mean. So it may be that this outcome is normal if Spotify considers a song a acoustic when one instrument appears to be acoustic, but we cannot be for certain. 


### Multivariate Analysis {data-width="650"}

```{r, echo=FALSE}
corpus_with_title <- 
  corpus %>%
  mutate(title = paste(track.album.name, " - ", track.name))


multi_plot_1 <- ggplot(corpus_with_title, aes(x = liveness, y = acousticness, color = speechiness, size = speechiness, label = title)) +
  geom_jitter(alpha = 0.7, width = 0.1) +
  theme_classic() + 
  scale_color_viridis_c() + 
  guides(size = "none") +
  labs(title = "Comparison of Liveness, Acousticness and Speechness",
       subtitle = "The plot consists of the liveness, acousticness and speechness of all individual songs"
  ) + 
  theme(
    legend.position = "Bottom"
  )

ggplotly(multi_plot_1, tooltip = c("x", "y", "label", "size"))
```

## Row  {.tabset .tabset-fade style="min-height:600px"}

### Energy Ranking

```{r, echo=FALSE}
corpus_energy <- corpus %>% 
  group_by(track.album.name) %>%
  summarize(album_energy=mean(energy))

global_mean <- mean(corpus$energy)

energy_plot_1 <- ggplot(corpus_energy, aes(x = album_energy, y = reorder(track.album.name, album_energy), color = album_energy)) +
  geom_point(size = 3) +
  geom_vline(xintercept = global_mean, color = "grey40", linetype = 3) +
  geom_segment(aes(xend = 0, yend = track.album.name), size = 2) + 
  theme_classic() +
  theme(legend.position = 'none', plot.margin = margin(l = -1000, r = 0, t = 0, b = 0, unit = "pt")) +
  labs(x = "Album's Mean Energy",
       y = "Album",
       title = "Albums ranked on their mean energy level") + 
  annotate(
    "text",
    x = global_mean + 0.06, y = 8,
    label = "Global\nmean",
    vjust = 1, size = 3, color = "grey40"
  ) +
  theme(
    axis.line.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.subtitle = element_text(size = 9)
  )
  

ggplotly(energy_plot_1)

```

### Acousticness Ranking

```{r, echo=FALSE}
corpus_acousticness <- corpus %>% 
  group_by(track.album.name) %>%
  summarize(album_acousticness=mean(acousticness))

global_mean <- mean(corpus$acousticness)

acousticness_plot_1 <- ggplot(corpus_acousticness, aes(x = album_acousticness, y = reorder(track.album.name, album_acousticness), color = album_acousticness)) +
  geom_point(size = 3) +
  geom_vline(xintercept = global_mean, color = "grey40", linetype = 3) +
  geom_segment(aes(xend = 0, yend = track.album.name), size = 2) + 
  theme_classic() +
  theme(legend.position = 'none', plot.margin = margin(l = -1000, r = 0, t = 0, b = 0, unit = "pt")) +
  labs(x = "Album's Mean Acousticness",
       y = "Album",
       title = "Albums ranked on their mean acousticness level") + 
  annotate(
    "text",
    x = global_mean + 0.06, y = 8,
    label = "Global\nmean",
    vjust = 1, size = 3, color = "grey40"
  ) +
  theme(
    axis.line.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.subtitle = element_text(size = 9)
  ) +
  scale_color_gradient(low = "red", high = "orange")
  

ggplotly(acousticness_plot_1)

```

## Row

### All Genres and Their Frequency

```{r, echo=FALSE}
input_genres <- list()

for (i in artistAlbumGenre_df$genre) {
  for (j in i) {
    input_genres <- append(input_genres, j)
  }
}

input_genres <- data.frame(genre=unlist(input_genres))

genresPlot <- ggplot(input_genres, aes(genre)) + 
  stat_count(color = "black", fill = "skyblue", width=0.5, position = "dodge") +
  labs(title = "Genre Distribution",
       x = "Genre",
       y = "Frequency") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10))

ggplotly(genresPlot)
```

# Album & Genre Comparisons {data-navmenu="Analysis" data-orientation=rows}

## Row {style="min-height:300px"}

### Rock vs Ambient

In the plot below I compared the rock albums "World Is Yours", "MASS OF THE FERMENTING DREGS", "T H E", "醜奴兒" and "In Rainbows" to the ambient albums "A I A: Alien Observer", "Building a Better World", "Music Has The Right To Children", "小圈子" and "新しい日の誕生". 
As you might notice, the genres in the [appendix](#corpus) do not directly classify some of the albums as rock or ambient. This is due to the way that Spotify classifies genres, you see, Spotify assigns a genre to the artist, not the album. Furthermore, Spotify is also very specific when it comes to genres resulting in a large sum of non matching genres (see the [genre distrubution plot](#global-analysis)). That is why i used the Spotify genres in combination with the genres classified by one of the largest music database: [Rate Your Music](https://rateyourmusic.com/).

The resulting right plot gives a surprising result; the mean tempo (and it's standard deviation) of ambient and rock are not far off. While it does appear that ambient is slightly shifted to a lower bpm than rock, they are still very close. 
Where we can see a difference is in the volume and duration; ambient tracks appear to be longer and at a lower volume than rock. 

The left plot tells a different story, it shows that there is quite a bit of variation between rock and ambient when it comes to the different octaves and their timber, which is most noticeable at c01, c02, c05 and c06. This might give a clue as to why the genres appear so similar in the right plot, yet sound and feel so different.


## Row {style="min-height:600px"}

``` {r, echo=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```

### Tempo with Duration & Volume

``` {r, echo=FALSE}
aiaobserver <- filter(corpus, track.album.name %in% c("A I A: Alien Observer", "Building a Better World", "Music Has The Right To Children", "小圈子", "新しい日の誕生")) |> add_audio_analysis()

worldisyours <- filter(corpus, track.album.name %in% c("World Is Yours", "MASS OF THE FERMENTING DREGS", "T H E", "醜奴兒", "In Rainbows")) |> add_audio_analysis()

comp <-
  aiaobserver |>
  mutate(genre = "Ambient") |>
  bind_rows(worldisyours |> mutate(genre = "Rock"))

comp |>
  mutate(
    sections =
      map(
        sections,                                    
        summarise_at,
        vars(tempo, loudness, duration),             
        list(section_mean = mean, section_sd = sd)  
      )
  ) |>
  unnest(sections) |>
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = genre,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_minimal() +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    colour = "Genre",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  )

```

### Timbre Coeffiecients at Different Octaves

```{r, echo=FALSE}
comp |> mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) |>
  select(genre, timbre) |>
  compmus_gather_timbre() |>
  ggplot(aes(x = basis, y = value, fill = genre)) +
  geom_violin() +
  scale_fill_manual(values = c("#f3969a", "#78c2ad")) +
  labs(x = "Spotify Timbre Coefficients", y = "", fill = "Genre")

```

# Individual Songs {data-navmenu=Analysis data-orientation=rows}

## Row

### Chroma Analysis of selected songs
Below are chroma plots showing interesting patterns in selected songs from my corpus.

##### Fishmans - LONG SEASON
LONG SEASON is a 35.17 minutes song that contains multiple sections that flow into each other. At the red lines a clear transition between these sections is visible. Although there are more, some sections blend over such a long period that the transitions become hard to annotate (as is visible in the section after the first red line)

##### F# A# ∞ - The Dead Flag Blues
The Dead Flag Blues another example of a song that is unique in it's presentation. It sets an ominous stage trough it use of multiple monologue sections. This is further emphasized in the annotated section (between the red lines); a long, slow decending scale followed by an ascending  scale over a period of around 400 seconds.

##### World is Yours - Nan Nan
World is your is the album with the highest average energy level and Nan Nan should be a very good example of that. However, the Chroma shows something slightly different; very fast sections followed by relatively slower section. This likely means that the fast sections and the instruments used are responsible for the high energy levels.


##### Drowning in the sewer - Hopelessness/ Slowdeath
Hoplessness and Slowdeath are both by the same artist, whose genre is hard to define but lays somewhere between ambient and breakcore. The cool thing about these two Chorma's is that both genres are clearly visible. The Darker sections are more ambient and slow, whilst the bright sections lean more towards breakcore and are very fast.

## Column {.tabset .tabset-fade}

### LONG SEASON Chroma

```{r, echo=FALSE, fig.width=15, fig.height=4}
# Hopelessness 5gTGFOB8RIihsPxfIC0OtH
## Slowdeath 1BeXGCZcCtfnW6stIaat1M
# Romantic Menory 1 624OIP4GiJDuDzlnm6j3Eo
# Daikaze... 52jaRS6n9DXbgf0Hd1sxlh
# No Suprises 10nyNJ6zNy2YVYLrcwLccB
# shine on you crazy diamonds 32dnKMni3I3gwUbWp4mi45
# small ... kid 6hUeV1owXYwGT0iKQH5hg4
# roygbiv 5Hf2h59YLInKlic7ooWZVd
# ... natsu 2dFUtZtpWydAU4QMmUOK47
# Building stream... nor. 6K8J4txeZp5anMIE0srVqr
# Building stream... alter. 6YluFLtLKCjW5hajXJj5oC
# building a better world [-1] 6wemF0lNDZUnZE4DE2BD0t
# jvnko loves you 2EBjkOHOH7HBh1smT7pTb1
## the dead flag blues 0YzMEu5sGNX0JKr9mdBtzd
# weird fishes 4wajJ1o7jWIg62YqpkHC7S
# only shallow 1KKuoYESWoUGsau6YYoEMl
# artsick 7Jzw6ZqrFefr5KlrQzgGJr
# 99.974 1bhmtYR8dE9XtRAJzQwbZe
## Nan Nan 3ICD0niQsK2ngW9zDbYlkI

rainseason <-
  get_tidy_audio_analysis("08b1bCjsKjMzhjBm0qhkof") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches, timbre)

rainseason |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  geom_vline(xintercept = 150, color = "green", size = 2) +
  geom_vline(xintercept = 1010, color = "red", size = 2) +
  geom_vline(xintercept = 1240, color = "red", size = 2) +
  geom_vline(xintercept = 1565, color = "orange", size = 2) +
  geom_vline(xintercept = 1670, color = "orange", size = 2) +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

```

### The Dead Flag Blues Chroma

```{r, echo=FALSE, fig.width=15, fig.height=4}
thedeadflagblues <-
  get_tidy_audio_analysis("0YzMEu5sGNX0JKr9mdBtzd") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

thedeadflagblues |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  geom_vline(xintercept = 395, color = "red", size = 2) +
  geom_vline(xintercept = 608, color = "red", size = 2) +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

```

### Nan Nan Chroma

```{r, echo=FALSE, fig.width=15, fig.height=4}
nannan <-
  get_tidy_audio_analysis("3ICD0niQsK2ngW9zDbYlkI") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

nannan |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  geom_vline(xintercept = 20, color = "green", size = 2) +
  geom_vline(xintercept = 40, color = "orange", size = 2) +
  geom_vline(xintercept = 63, color = "orange", size = 2) +
  geom_vline(xintercept = 83, color = "red", size = 2) +
  geom_vline(xintercept = 120, color = "red", size = 2) +
  theme_minimal() +
  scale_fill_viridis_c()

```

### Hopelessness Chroma

```{r, echo=FALSE, fig.width=15, fig.height=4}
hopelessness <-
  get_tidy_audio_analysis("5gTGFOB8RIihsPxfIC0OtH") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

hopelessness |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  geom_vline(xintercept = 108, color = "red", size = 2) +
  geom_vline(xintercept = 155, color = "red", size = 2) +
  geom_vline(xintercept = 226, color = "green", size = 2) +
  geom_vline(xintercept = 272, color = "orange", size = 2) +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

```

### Slowdeath Chroma

```{r, echo=FALSE, fig.width=15, fig.height=4}
slowdeath <-
  get_tidy_audio_analysis("624OIP4GiJDuDzlnm6j3Eo") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

slowdeath |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  geom_vline(xintercept = 16, color = "green", size = 2) +
  geom_vline(xintercept = 68, color = "red", size = 2) +
  geom_vline(xintercept = 83, color = "red", size = 2) +
  geom_vline(xintercept = 101, color = "red", size = 2) +
  geom_vline(xintercept = 115, color = "red", size = 2) +
  geom_vline(xintercept = 127, color = "green", size = 2) +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

```

## Row {style="min-height:600px"}

### Dynamic Time Wrapping

In Underwater DTW I have compared the live version of underwater by elephant gym to their studio performance. The graph shows us that the two versions are very similar to each other by the apparent diagonal line.
That the 2 versions are so similar is not strange at all as Underwater is a math-rock song. This means that the song is performed by a band where typically the drummer and/or the bass decides the rhythm and tempo at which the whole band plays. If the rhythm/tempo is slightly off the whole song will 'fall apart', so keeping a consistent rhythm and tempo is crucial to a performance.
That being said, the 2 songs do still differ, just not in rhythm or tempo. Rather, they differ in timber and sound stage. likely due to how/where they were recorded and things like the effects the instruments used (a.e. guitar pedals) or ones that were added later.



### Underwater DTW

```{r, echo=FALSE}
# underwater live 01aYWPwgS52VhujkRnQn6p
# underwater 3bZaxtkOP7zxmHtS3d4n2X
# finger live 5KufVu7rjJXEBCFuvaXaeF
# finger 7ejqDX4cLKQ915nrtnbZO4

underwater <-
  get_tidy_audio_analysis("3bZaxtkOP7zxmHtS3d4n2X") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

underwater_live <-
  get_tidy_audio_analysis("01aYWPwgS52VhujkRnQn6p") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

compmus_long_distance(
  underwater |> mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  underwater_live |> mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "euclidean"
) |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "Underwater", y = "Underwater live version") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)


```

## Row 

### Analysis of the Timber and Chroma of 進化 by 猫 シ Corp. and t e l e p a t h テレパシー能力者 {style="min-height:600px"}

The Self-similarity plot shows the timber and chromagram of 進化 by 猫 シ Corp. and t e l e p a t h テレパシー能力者. I chose this song as it was has the highest liveness recorded by Spotify of any song in the corpus (see Plot A on the 'Global Analysis' tab). 
What is interesting about this classification is that this song is not a live recording in the slightest. Then, why? well, the classification is likely due to the apparent outside noise in the song, you see, 進化 (translated = evolution) is an ambient focused song that incorporates sounds like fire and noise from train stations. This likely confuses the Spotify algorithm to where it classifies the song incorrectly as having a high liveness.
The Timbre and Chroma similarity matrix sadly don't really bring forth the liveness, however, they do show the repeating pattern in the song very clearly. The Chroma creates an almost checkerboard like structure, whilst the timbre shows fade in and fade out that the song makes. This fading pattern is especially visible towards the beginning and start of the song.

### Self-similarity Timber and Chromagram {style="min-height=600px"}

```{r, echo=FALSE}

# BaBW eennaarlaatstetrack 6wemF0lNDZUnZE4DE2BD0t

evolution <-
  get_tidy_audio_analysis("6wemF0lNDZUnZE4DE2BD0t") |>
  compmus_align(bars, segments) |>
  select(bars) |>
  unnest(bars) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  evolution |>
    compmus_self_similarity(pitches, "aitchison") |>
    mutate(d = d / max(d), type = "Chroma"),
  evolution |>
    compmus_self_similarity(timbre, "euclidean") |>
    mutate(d = d / max(d), type = "Timbre")
) |>
  mutate() |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```

## Row {style="min-height:400px"}

### The Color Of Fire {data-width="350" style="min-height:150px"}

"The Color Of Fire" by Boards of Canada is a perfect representation of the surrealistic, creepy and weirdly nostalgic feeling that the album "Music Has the Right to Children" presents. 
The song has a clear progression, starting at B7, then Eb seventh, Gb seventh, Ab seventh and back to B7 (followed by a fade off), which the Chordogram plotted below shows very clearly.

### Chordogram - The Color Of Fire

```{r, echo=FALSE, fig.width=13}
thecoloroffire <-
  get_tidy_audio_analysis("5dm5vtne8lx8BPrVamK6S1") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
    )

thecoloroffire |>
  compmus_match_pitch_template(
    chord_templates,
    method = "euclidean",
    norm = "manhattan"
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "") +
  geom_vline(xintercept = 9, color = "red", size = 2) + 
  geom_vline(xintercept = 45, color = "orange", size = 2) + 
  geom_vline(xintercept = 60, color = "green", size = 2) + 
  geom_vline(xintercept = 79, color = "magenta", size = 2)  
  

```

# Findings

## Column

### Nothing Here Yet

#### :)
